Total train data points: 607, Won: 42.17462932454695%, Lost: 34.102141680395384%, Draw: 23.72322899505766%
Total val data points: 76, Won: 36.8421052631579%, Lost: 39.473684210526315%, Draw: 23.68421052631579%
Total test data points: 76, Won: 40.78947368421053%, Lost: 42.10526315789474%, Draw: 17.105263157894736%
GNN model, data {} 0
Continuous evaluation
T:0, train_loss:1.09724, train_acc:0.33704, val_loss=1.09875, val_acc=0.34259
T:1, train_loss:1.09865, train_acc:0.30000, val_loss=1.09876, val_acc=0.34105
T:2, train_loss:1.09103, train_acc:0.40140, val_loss=1.09864, val_acc=0.34568
T:3, train_loss:1.08830, train_acc:0.35453, val_loss=1.09661, val_acc=0.34259
T:4, train_loss:1.07870, train_acc:0.38187, val_loss=1.09312, val_acc=0.34621
T:5, train_loss:1.07167, train_acc:0.38177, val_loss=1.08882, val_acc=0.32915
T:6, train_loss:1.06170, train_acc:0.39316, val_loss=1.08576, val_acc=0.32432
T:7, train_loss:1.05131, train_acc:0.38750, val_loss=1.09853, val_acc=0.32419
T:8, train_loss:1.02350, train_acc:0.42469, val_loss=1.11740, val_acc=0.32242
T:9, train_loss:1.02097, train_acc:0.42972, val_loss=1.13486, val_acc=0.30066
T:10, train_loss:1.04456, train_acc:0.49593, val_loss=1.16077, val_acc=0.35582
T:11, train_loss:1.00807, train_acc:0.54765, val_loss=1.12689, val_acc=0.42123
T:12, train_loss:0.99776, train_acc:0.56410, val_loss=1.14627, val_acc=0.40522
T:13, train_loss:0.97956, train_acc:0.55052, val_loss=1.12384, val_acc=0.41873
T:14, train_loss:0.97567, train_acc:0.57145, val_loss=1.16348, val_acc=0.42729
T:15, train_loss:0.97605, train_acc:0.57176, val_loss=1.17936, val_acc=0.42336
T:16, train_loss:0.96885, train_acc:0.54015, val_loss=1.14382, val_acc=0.45455
T:17, train_loss:0.96972, train_acc:0.55982, val_loss=1.15322, val_acc=0.46415
T:18, train_loss:0.95723, train_acc:0.55639, val_loss=1.14374, val_acc=0.47793
T:19, train_loss:0.95301, train_acc:0.55569, val_loss=1.13208, val_acc=0.47266
T:20, train_loss:0.95836, train_acc:0.54888, val_loss=1.24921, val_acc=0.47316
T:21, train_loss:0.95496, train_acc:0.54618, val_loss=1.17450, val_acc=0.46356
T:22, train_loss:0.95417, train_acc:0.54466, val_loss=1.28036, val_acc=0.45979
T:23, train_loss:0.94731, train_acc:0.55588, val_loss=1.19442, val_acc=0.49790
T:24, train_loss:0.94980, train_acc:0.55245, val_loss=1.31831, val_acc=0.47966
T:25, train_loss:0.96068, train_acc:0.54522, val_loss=1.34271, val_acc=0.46725
T:26, train_loss:0.94879, train_acc:0.56809, val_loss=1.23366, val_acc=0.48107
T:27, train_loss:0.94171, train_acc:0.56875, val_loss=1.27243, val_acc=0.47045
T:28, train_loss:0.92507, train_acc:0.58220, val_loss=1.21714, val_acc=0.47564
T:29, train_loss:0.91834, train_acc:0.58915, val_loss=1.30452, val_acc=0.48815
T:30, train_loss:0.93621, train_acc:0.58315, val_loss=1.33130, val_acc=0.49153
T:31, train_loss:0.92418, train_acc:0.58923, val_loss=1.26560, val_acc=0.48267
T:32, train_loss:0.92814, train_acc:0.58735, val_loss=1.34065, val_acc=0.43544
T:33, train_loss:0.90507, train_acc:0.60294, val_loss=1.27788, val_acc=0.46373
T:34, train_loss:0.90036, train_acc:0.60462, val_loss=1.31974, val_acc=0.48541
T:35, train_loss:0.90624, train_acc:0.60753, val_loss=1.33004, val_acc=0.45652
T:36, train_loss:0.89104, train_acc:0.61268, val_loss=1.25971, val_acc=0.44568
T:37, train_loss:0.90584, train_acc:0.60566, val_loss=1.31326, val_acc=0.46286
T:38, train_loss:0.91015, train_acc:0.59978, val_loss=1.36207, val_acc=0.47214
T:39, train_loss:0.92347, train_acc:0.59621, val_loss=1.26416, val_acc=0.42470
T:40, train_loss:0.92977, train_acc:0.57908, val_loss=1.28970, val_acc=0.43344
T:41, train_loss:0.91403, train_acc:0.59091, val_loss=1.27108, val_acc=0.45541
T:42, train_loss:0.89613, train_acc:0.60156, val_loss=1.26470, val_acc=0.45246
T:43, train_loss:0.88691, train_acc:0.60748, val_loss=1.29668, val_acc=0.49324
T:44, train_loss:0.90217, train_acc:0.60039, val_loss=1.26547, val_acc=0.48780
T:45, train_loss:0.91066, train_acc:0.59276, val_loss=1.30081, val_acc=0.46403
T:46, train_loss:0.91906, train_acc:0.59855, val_loss=1.25533, val_acc=0.45353
T:47, train_loss:0.93974, train_acc:0.57748, val_loss=1.24481, val_acc=0.47308
T:48, train_loss:0.92503, train_acc:0.58906, val_loss=1.31185, val_acc=0.48606
T:49, train_loss:0.92763, train_acc:0.58651, val_loss=1.31411, val_acc=0.47107
T:50, train_loss:0.91883, train_acc:0.59163, val_loss=1.30227, val_acc=0.48069
T:51, train_loss:0.91527, train_acc:0.59651, val_loss=1.35914, val_acc=0.43304
T:52, train_loss:0.92996, train_acc:0.58585, val_loss=1.31587, val_acc=0.43256
T:53, train_loss:0.92074, train_acc:0.58844, val_loss=1.27912, val_acc=0.47087
T:54, train_loss:0.92072, train_acc:0.58079, val_loss=1.27060, val_acc=0.45178
T:55, train_loss:0.93707, train_acc:0.57838, val_loss=1.34461, val_acc=0.44681
T:56, train_loss:0.94438, train_acc:0.58386, val_loss=1.28778, val_acc=0.45810
T:57, train_loss:0.95387, train_acc:0.56995, val_loss=1.17865, val_acc=0.47647
T:58, train_loss:0.97008, train_acc:0.54887, val_loss=1.18283, val_acc=0.40373
T:59, train_loss:0.97861, train_acc:0.55086, val_loss=1.20703, val_acc=0.44737
T:60, train_loss:0.96437, train_acc:0.56001, val_loss=1.18043, val_acc=0.46853
T:61, train_loss:0.96189, train_acc:0.55736, val_loss=1.21244, val_acc=0.46269
T:62, train_loss:0.95487, train_acc:0.57447, val_loss=1.17258, val_acc=0.48000
T:63, train_loss:0.95285, train_acc:0.57338, val_loss=1.18492, val_acc=0.51724
T:64, train_loss:0.95034, train_acc:0.57338, val_loss=1.20059, val_acc=0.49533
T:65, train_loss:0.94073, train_acc:0.58826, val_loss=1.20546, val_acc=0.46939
T:66, train_loss:0.95946, train_acc:0.57386, val_loss=1.16879, val_acc=0.46067
T:67, train_loss:0.95808, train_acc:0.57435, val_loss=1.15012, val_acc=0.50000
T:68, train_loss:0.95410, train_acc:0.56423, val_loss=1.11666, val_acc=0.52113
T:69, train_loss:0.94746, train_acc:0.56007, val_loss=1.10139, val_acc=0.51613
T:70, train_loss:0.96720, train_acc:0.55279, val_loss=1.11551, val_acc=0.50943
T:71, train_loss:0.95728, train_acc:0.56104, val_loss=1.11039, val_acc=0.50000
T:72, train_loss:0.94905, train_acc:0.56911, val_loss=1.04646, val_acc=0.54286
T:73, train_loss:0.94433, train_acc:0.56969, val_loss=1.00032, val_acc=0.57692
T:74, train_loss:0.95629, train_acc:0.55355, val_loss=0.96331, val_acc=0.70588
T:75, train_loss:0.94663, train_acc:0.56321, val_loss=0.97232, val_acc=0.75000
0.4624020321667546
accuracy on testing data is: 0.5